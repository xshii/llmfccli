# -*- coding: utf-8 -*-
"""
Command-line interface for Claude-Qwen
"""

import sys
import os
from pathlib import Path
from typing import Optional

from prompt_toolkit import PromptSession
from prompt_toolkit.history import FileHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel

from .agent.loop import AgentLoop
from .llm.client import OllamaClient
from .utils.precheck import PreCheck


class CLI:
    """Interactive CLI for Claude-Qwen"""
    
    def __init__(self, project_root: Optional[str] = None, skip_precheck: bool = False):
        """Initialize CLI

        Args:
            project_root: Project root directory
            skip_precheck: Skip environment pre-check (for testing)
        """
        self.console = Console()
        self.project_root = project_root or str(Path.cwd())

        # Run pre-check unless explicitly skipped
        if not skip_precheck:
            self._run_precheck()

        # Initialize agent
        self.client = OllamaClient()
        self.agent = AgentLoop(self.client, self.project_root)

        # Setup prompt session
        history_file = Path.home() / '.claude_qwen_history'
        self.session = PromptSession(
            history=FileHistory(str(history_file)),
            auto_suggest=AutoSuggestFromHistory(),
        )
    
    def _run_precheck(self):
        """Run environment pre-check"""
        self.console.print("\n[cyan]è¿è¡Œç¯å¢ƒæ£€æŸ¥...[/cyan]\n")

        # Run pre-checks (skip project structure check)
        results = []
        results.append(PreCheck.check_ssh_tunnel())
        results.append(PreCheck.check_ollama_connection())
        results.append(PreCheck.check_ollama_model(model_name="qwen3:latest"))

        # Display results
        all_passed = all(r.success for r in results)

        for result in results:
            status = "âœ“" if result.success else "âœ—"
            color = "green" if result.success else "red"
            self.console.print(f"[{color}]{status}[/{color}] {result.message}")

        if not all_passed:
            self.console.print("\n[yellow]âš  ç¯å¢ƒæ£€æŸ¥å¤±è´¥[/yellow]")
            self.console.print("\n[yellow]å»ºè®®æ“ä½œ:[/yellow]")

            for result in results:
                if not result.success:
                    if "SSH Tunnel" in result.name:
                        self.console.print("  â€¢ å¯åŠ¨ SSH éš§é“: [cyan]ssh -fN ollama-tunnel[/cyan]")
                    elif "Ollama Connection" in result.name:
                        self.console.print("  â€¢ éªŒè¯è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ")
                    elif "Ollama Model" in result.name:
                        model = result.details.get('model', 'qwen3:latest')
                        self.console.print(f"  â€¢ æ‹‰å–æ¨¡å‹: [cyan]ollama pull {model}[/cyan]")

            self.console.print("\n[yellow]æç¤º: ä½¿ç”¨ --skip-precheck å‚æ•°è·³è¿‡ç¯å¢ƒæ£€æŸ¥[/yellow]\n")

            # Ask user if they want to continue
            try:
                response = input("æ˜¯å¦ç»§ç»­? (y/N): ").strip().lower()
                if response not in ['y', 'yes']:
                    self.console.print("[red]å·²å–æ¶ˆå¯åŠ¨[/red]")
                    sys.exit(1)
            except (KeyboardInterrupt, EOFError):
                self.console.print("\n[red]å·²å–æ¶ˆå¯åŠ¨[/red]")
                sys.exit(1)
        else:
            self.console.print("\n[green]âœ“ ç¯å¢ƒæ£€æŸ¥é€šè¿‡[/green]\n")

    def show_welcome(self):
        """Show welcome message"""
        stream_status = "âœ“ å¯ç”¨" if self.client.stream_enabled else "âœ— ç¦ç”¨"
        stream_hint = "(å®æ—¶è¾“å‡º)" if self.client.stream_enabled else "(ç­‰å¾…å®Œæ•´å“åº”)"

        welcome = """
# Claude-Qwen AI ç¼–ç¨‹åŠ©æ‰‹

**é¡¹ç›®æ ¹ç›®å½•**: {root}
**æµå¼è¾“å‡º**: {stream_status} {stream_hint}

**å¯ç”¨å‘½ä»¤**:
- `/help` - æ˜¾ç¤ºå¸®åŠ©
- `/clear` - æ¸…é™¤å¯¹è¯å†å²ï¼ˆä¿ç•™æ–‡ä»¶è®¿é—®ï¼‰
- `/compact` - æ‰‹åŠ¨å‹ç¼©ä¸Šä¸‹æ–‡
- `/usage` - æ˜¾ç¤º Token ä½¿ç”¨æƒ…å†µ
- `/exit` - é€€å‡º

**å¿«é€Ÿå¼€å§‹**: ç›´æ¥è¾“å…¥æ‚¨çš„è¯·æ±‚ï¼Œä¾‹å¦‚ï¼š
- "æ‰¾åˆ° network_handler.cpp å¹¶æ·»åŠ è¶…æ—¶é‡è¯•æœºåˆ¶"
- "ç¼–è¯‘é¡¹ç›®å¹¶ä¿®å¤é”™è¯¯"
- "ä¸ºå½“å‰æ–‡ä»¶ç”Ÿæˆå•å…ƒæµ‹è¯•"

ğŸ’¡ ä¿®æ”¹ `config/ollama.yaml` ä¸­çš„ `stream` é…ç½®å¯åˆ‡æ¢è¾“å‡ºæ¨¡å¼
"""
        self.console.print(Panel(
            Markdown(welcome.format(
                root=self.project_root,
                stream_status=stream_status,
                stream_hint=stream_hint
            )),
            title="æ¬¢è¿",
            border_style="blue"
        ))
    
    def run(self):
        """Run interactive loop"""
        self.show_welcome()
        
        while True:
            try:
                # Get user input
                user_input = self.session.prompt('\n> ').strip()
                
                if not user_input:
                    continue
                
                # Handle commands
                if user_input.startswith('/'):
                    if not self.handle_command(user_input):
                        break
                    continue
                
                # Execute task
                self.console.print("\n[cyan]æ‰§è¡Œä¸­...[/cyan]\n")

                try:
                    # Check if streaming is enabled in config
                    stream_enabled = self.client.stream_enabled

                    if stream_enabled:
                        # Streaming mode: real-time output
                        streamed_content = []

                        def on_chunk(chunk: str):
                            """Callback for streaming chunks"""
                            streamed_content.append(chunk)
                            # Print chunk in real-time
                            self.console.print(chunk, end='', style="white")

                        # Run with streaming enabled
                        response = self.agent.run(user_input, stream=True, on_chunk=on_chunk)

                        # Print newline after streaming
                        self.console.print("\n")

                        # If response is empty (fully streamed), use streamed content
                        if not response.strip() and streamed_content:
                            response = ''.join(streamed_content)
                    else:
                        # Non-streaming mode: wait for complete response
                        response = self.agent.run(user_input, stream=False)

                        # Display response in panel
                        self.console.print(Panel(
                            Markdown(response),
                            title="å“åº”",
                            border_style="green"
                        ))

                except Exception as e:
                    self.console.print(f"[red]é”™è¯¯: {e}[/red]")
                
            except KeyboardInterrupt:
                self.console.print("\n[yellow]å·²å–æ¶ˆ[/yellow]")
                continue
            except EOFError:
                break
        
        self.console.print("\n[blue]å†è§![/blue]")
    
    def handle_command(self, command: str) -> bool:
        """
        Handle slash commands
        
        Returns:
            False to exit, True to continue
        """
        cmd = command.lower().split()[0]
        
        if cmd == '/exit' or cmd == '/quit':
            return False
        
        elif cmd == '/help':
            self.show_help()
        
        elif cmd == '/clear':
            self.agent.conversation_history.clear()
            self.agent.tool_calls.clear()
            self.console.print("[green]å·²æ¸…é™¤å¯¹è¯å†å²[/green]")
        
        elif cmd == '/compact':
            self.console.print("[cyan]å‹ç¼©ä¸­...[/cyan]")
            self.agent._compress_context()
            self.console.print("[green]å‹ç¼©å®Œæˆ[/green]")
            self.console.print(self.agent.get_usage_report())
        
        elif cmd == '/usage':
            report = self.agent.get_usage_report()
            self.console.print(Panel(report, title="Token ä½¿ç”¨æƒ…å†µ"))
        
        elif cmd == '/root':
            parts = command.split(maxsplit=1)
            if len(parts) > 1:
                new_root = parts[1]
                if os.path.exists(new_root):
                    self.project_root = os.path.abspath(new_root)
                    self.agent.set_project_root(self.project_root)
                    self.console.print(f"[green]é¡¹ç›®æ ¹ç›®å½•å·²è®¾ç½®ä¸º: {self.project_root}[/green]")
                else:
                    self.console.print(f"[red]ç›®å½•ä¸å­˜åœ¨: {new_root}[/red]")
            else:
                self.console.print(f"å½“å‰é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
        else:
            self.console.print(f"[yellow]æœªçŸ¥å‘½ä»¤: {cmd}[/yellow]")
            self.console.print("è¾“å…¥ /help æŸ¥çœ‹å¯ç”¨å‘½ä»¤")
        
        return True
    
    def show_help(self):
        """Show help message"""
        help_text = """
## å¯ç”¨å‘½ä»¤

- `/help` - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯
- `/clear` - æ¸…é™¤å¯¹è¯å†å²ï¼ˆä¿ç•™æ–‡ä»¶è®¿é—®æƒé™ï¼‰
- `/compact` - æ‰‹åŠ¨è§¦å‘ä¸Šä¸‹æ–‡å‹ç¼©
- `/usage` - æ˜¾ç¤º Token ä½¿ç”¨æƒ…å†µ
- `/root [path]` - æŸ¥çœ‹æˆ–è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
- `/exit` æˆ– `/quit` - é€€å‡ºç¨‹åº

## ç¤ºä¾‹ç”¨æ³•

**æ–‡ä»¶æ“ä½œ**:
```
æ‰¾åˆ° network_handler.cpp å¹¶æ·»åŠ è¶…æ—¶é‡è¯•æœºåˆ¶
```

**ç¼–è¯‘ä¿®å¤**:
```
ç¼–è¯‘é¡¹ç›®å¹¶ä¿®å¤æ‰€æœ‰é”™è¯¯
```

**æµ‹è¯•ç”Ÿæˆ**:
```
ä¸ºå½“å‰æ–‡ä»¶ç”Ÿæˆå•å…ƒæµ‹è¯•
åˆ†æ HTTP æ¨¡å—å¹¶ç”Ÿæˆé›†æˆæµ‹è¯•
```

**ä»£ç åˆ†æ**:
```
åˆ†æé¡¹ç›®ç»“æ„
æŸ¥æ‰¾æ‰€æœ‰ç½‘ç»œç›¸å…³çš„å‡½æ•°
```
"""
        self.console.print(Panel(Markdown(help_text), title="å¸®åŠ©"))


def main():
    """Main entry point"""
    import argparse

    parser = argparse.ArgumentParser(description='Claude-Qwen AI ç¼–ç¨‹åŠ©æ‰‹')
    parser.add_argument('--root', '-r', help='é¡¹ç›®æ ¹ç›®å½•', default=None)
    parser.add_argument('--skip-precheck', action='store_true',
                        help='è·³è¿‡ç¯å¢ƒé¢„æ£€æŸ¥ï¼ˆç”¨äºæµ‹è¯•æˆ–ç¦»çº¿ç¯å¢ƒï¼‰')
    parser.add_argument('--version', '-v', action='version', version='0.1.0')

    args = parser.parse_args()

    # Initialize and run CLI
    cli = CLI(project_root=args.root, skip_precheck=args.skip_precheck)

    try:
        cli.run()
    except Exception as e:
        print(f"Fatal error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
