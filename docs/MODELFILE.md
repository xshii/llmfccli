# Modelfile ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`claude-qwen:latest` æ˜¯åŸºäº `qwen3:latest` çš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œå›ºåŒ–äº† system prompt å’Œå‚æ•°é…ç½®ã€‚

## ä¸ºä»€ä¹ˆä½¿ç”¨ Modelfileï¼Ÿ

### âœ… ä¼˜åŠ¿

1. **é…ç½®é›†ä¸­**ï¼šSystem prompt å’Œå‚æ•°å›ºåŒ–åœ¨æ¨¡å‹ä¸­
2. **èŠ‚çœ tokens**ï¼šæ— éœ€æ¯æ¬¡è¯·æ±‚éƒ½ä¼ é€’ system message
3. **å›¢é˜Ÿç»Ÿä¸€**ï¼šæ‰€æœ‰äººä½¿ç”¨ç›¸åŒçš„æ¨¡å‹é…ç½®
4. **ç»§æ‰¿èƒ½åŠ›**ï¼šå®Œå…¨ç»§æ‰¿ qwen3 çš„ tool calling èƒ½åŠ›

### ğŸ¯ è®¾è®¡åŸåˆ™

- **ä¸è¦†ç›– TEMPLATE**ï¼šç»§æ‰¿ qwen3 çš„ tool calling template
- **å›ºåŒ–é…ç½®**ï¼šSYSTEM + PARAMETER åœ¨ Modelfile ä¸­
- **ç®€åŒ–ä»£ç **ï¼šä»£ç ä¸­ä¸éœ€è¦ä¼ é€’ system message

## æ–‡ä»¶ç»“æ„

```
llmfccli/
â”œâ”€â”€ Modelfile.claude-qwen      # è‡ªå®šä¹‰æ¨¡å‹å®šä¹‰
â”œâ”€â”€ config/ollama.yaml          # è¿è¡Œæ—¶é…ç½®ï¼ˆå¯è¦†ç›–ï¼‰
â””â”€â”€ backend/
    â”œâ”€â”€ llm/prompts.py          # å…¶ä»– prompt æ¨¡æ¿ï¼ˆä¿ç•™å¤‡ç”¨ï¼‰
    â””â”€â”€ agent/loop.py           # ç®€åŒ–åçš„ä»£ç 
```

## Modelfile å†…å®¹

```dockerfile
FROM qwen3:latest

# å›ºåŒ– System Promptï¼ˆä¸å†éœ€è¦ä»£ç ä¼ å…¥ï¼‰
SYSTEM """
[C++ ç¼–ç¨‹åŠ©æ‰‹çš„è¯¦ç»†è¯´æ˜]
"""

# å›ºåŒ–å‚æ•°
PARAMETER temperature 0.7
PARAMETER num_ctx 131072
...

# ä¸æ·»åŠ  TEMPLATE - ç»§æ‰¿ qwen3 çš„ tool calling template
```

**å…³é”®**ï¼šæ²¡æœ‰ `TEMPLATE` æŒ‡ä»¤ â†’ è‡ªåŠ¨ç»§æ‰¿ qwen3 çš„å®Œæ•´ templateï¼ˆåŒ…æ‹¬ `{{ .Tools }}`ï¼‰

## åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹

### é¦–æ¬¡åˆ›å»º

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•
ollama create claude-qwen:latest -f Modelfile.claude-qwen
```

### éªŒè¯åˆ›å»º

```bash
# æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨
ollama list | grep claude-qwen

# æŸ¥çœ‹æ¨¡å‹é…ç½®
ollama show claude-qwen:latest --modelfile
```

è¾“å‡ºåº”è¯¥åŒ…å«ï¼š
- `FROM qwen3:latest`
- `SYSTEM "..."`
- `PARAMETER ...`
- **æ²¡æœ‰** `TEMPLATE` æŒ‡ä»¤ï¼ˆç»§æ‰¿è‡ª qwen3ï¼‰

## æ›´æ–°æ¨¡å‹

å½“ä¿®æ”¹äº† `Modelfile.claude-qwen` åï¼š

```bash
# é‡æ–°åˆ›å»ºæ¨¡å‹ï¼ˆä¼šè¦†ç›–æ—§ç‰ˆæœ¬ï¼‰
ollama create claude-qwen:latest -f Modelfile.claude-qwen

# æˆ–è€…åˆ›å»ºæ–°ç‰ˆæœ¬
ollama create claude-qwen:v2 -f Modelfile.claude-qwen
```

## é…ç½®æ–‡ä»¶

### config/ollama.yaml

```yaml
ollama:
  model: "claude-qwen:latest"  # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹

  # ä»¥ä¸‹å‚æ•°å·²åœ¨ Modelfile ä¸­å›ºåŒ–
  # ä½†å¯ä»¥åœ¨è¿è¡Œæ—¶è¦†ç›–
  generation:
    temperature: 0.7      # é»˜è®¤å€¼
    num_ctx: 131072       # é»˜è®¤å€¼
```

## ä»£ç ç®€åŒ–

### ä¿®æ”¹å‰ï¼ˆåŠ¨æ€ä¼  systemï¼‰

```python
# backend/agent/loop.py
from ..llm.prompts import get_system_prompt

messages = [
    {'role': 'system', 'content': get_system_prompt()},  # æ¯æ¬¡éƒ½ä¼ 
    *self.conversation_history
]
```

### ä¿®æ”¹åï¼ˆModelfile å›ºåŒ–ï¼‰

```python
# backend/agent/loop.py
# System prompt å·²åœ¨ Modelfile ä¸­å›ºåŒ–
messages = list(self.conversation_history)  # ä¸éœ€è¦ä¼  system
```

**ç®€åŒ–äº†**ï¼š
- âŒ åˆ é™¤ `get_system_prompt()` è°ƒç”¨
- âŒ åˆ é™¤ system message æ„å»º
- âœ… ç›´æ¥ä½¿ç”¨å¯¹è¯å†å²

## Tool Calling å·¥ä½œæµç¨‹

```
ç”¨æˆ·è¯·æ±‚
    â†“
æ„å»º messagesï¼ˆåªåŒ…å«å¯¹è¯å†å²ï¼‰
    â†“
è°ƒç”¨ Ollama API
    â†“
Ollama è‡ªåŠ¨æ·»åŠ  Modelfile ä¸­çš„ SYSTEM
    â†“
ä½¿ç”¨ç»§æ‰¿çš„ qwen3 TEMPLATE å¤„ç† tools
    â†“
æ¨¡å‹ç”Ÿæˆ tool_calls
```

## å¸¸è§é—®é¢˜

### Q1: ä¿®æ”¹ system prompt éœ€è¦é‡æ–°åˆ›å»ºæ¨¡å‹å—ï¼Ÿ

**æ˜¯çš„**ã€‚ä¿®æ”¹ `Modelfile.claude-qwen` åéœ€è¦è¿è¡Œï¼š

```bash
ollama create claude-qwen:latest -f Modelfile.claude-qwen
```

### Q2: ä¼šç ´å tool calling åŠŸèƒ½å—ï¼Ÿ

**ä¸ä¼š**ã€‚å› ä¸ºæˆ‘ä»¬ï¼š
- âœ… æ²¡æœ‰æ·»åŠ  `TEMPLATE` æŒ‡ä»¤
- âœ… å®Œå…¨ç»§æ‰¿ qwen3 çš„ templateï¼ˆåŒ…æ‹¬ `{{ .Tools }}`ï¼‰
- âœ… Tool calling åŠŸèƒ½å®Œæ•´ä¿ç•™

### Q3: å¯ä»¥ä¸´æ—¶è¦†ç›–å‚æ•°å—ï¼Ÿ

**å¯ä»¥**ã€‚åœ¨ä»£ç ä¸­ä¼ é€’å‚æ•°ä¼šè¦†ç›– Modelfile çš„é»˜è®¤å€¼ï¼š

```python
response = client.chat(
    messages=messages,
    tools=tools,
    temperature=0.3  # ä¸´æ—¶è¦†ç›– Modelfile ä¸­çš„ 0.7
)
```

### Q4: ä¸ºä»€ä¹ˆä¸æŠŠ prompts.py åˆ é™¤ï¼Ÿ

**ä¿ç•™å¤‡ç”¨**ã€‚è™½ç„¶ system prompt å·²åœ¨ Modelfile ä¸­ï¼Œä½†å…¶ä»– prompt æ¨¡æ¿ï¼ˆå¦‚å‹ç¼©ã€é”™è¯¯æ¢å¤ï¼‰ä»ç„¶æœ‰ç”¨ã€‚

### Q5: å›¢é˜Ÿå…¶ä»–æˆå‘˜æ€ä¹ˆä½¿ç”¨ï¼Ÿ

**ä¸¤ç§æ–¹å¼**ï¼š

**æ–¹å¼ 1**ï¼šåˆ†å‘ Modelfile
```bash
# å…¶ä»–æˆå‘˜å…‹éš†ä»£ç å
ollama create claude-qwen:latest -f Modelfile.claude-qwen
```

**æ–¹å¼ 2**ï¼šå¯¼å‡ºæ¨¡å‹ï¼ˆæ¨èï¼‰
```bash
# åˆ›å»ºè€…å¯¼å‡º
ollama push your-org/claude-qwen:latest

# å…¶ä»–æˆå‘˜æ‹‰å–
ollama pull your-org/claude-qwen:latest
```

## æœ€ä½³å®è·µ

### 1. ç‰ˆæœ¬æ§åˆ¶

```bash
# å¼€å‘ç‰ˆ
ollama create claude-qwen:dev -f Modelfile.claude-qwen

# ç¨³å®šç‰ˆ
ollama create claude-qwen:latest -f Modelfile.claude-qwen

# å®éªŒç‰ˆ
ollama create claude-qwen:experimental -f Modelfile.claude-qwen
```

### 2. å‚æ•°è°ƒä¼˜

åœ¨ Modelfile ä¸­å›ºåŒ–**ç¨³å®š**çš„å‚æ•°ï¼š
```dockerfile
PARAMETER temperature 0.7      # ç¨³å®š
PARAMETER num_ctx 131072       # ç¨³å®š
```

åœ¨ä»£ç ä¸­ä¼ é€’**å®éªŒæ€§**å‚æ•°ï¼š
```python
response = client.chat(..., temperature=0.9)  # ä¸´æ—¶æµ‹è¯•
```

### 3. System Prompt ç»´æŠ¤

```
Modelfile.claude-qwen          # å½“å‰ç‰ˆæœ¬
Modelfile.claude-qwen.backup   # å¤‡ä»½
```

ä¿®æ”¹å‰å…ˆå¤‡ä»½ï¼š
```bash
cp Modelfile.claude-qwen Modelfile.claude-qwen.backup
```

## è¿ç§»æŒ‡å—

### ä» qwen3:latest è¿ç§»

1. åˆ›å»º `Modelfile.claude-qwen`
2. å¤åˆ¶ `backend/llm/prompts.py` ä¸­çš„ `SYSTEM_PROMPT`
3. å¤åˆ¶ `config/ollama.yaml` ä¸­çš„å‚æ•°
4. åˆ›å»ºæ¨¡å‹ï¼š`ollama create claude-qwen:latest -f Modelfile.claude-qwen`
5. ä¿®æ”¹é…ç½®ï¼š`model: "claude-qwen:latest"`
6. ç®€åŒ–ä»£ç ï¼šåˆ é™¤ `get_system_prompt()` è°ƒç”¨
7. æµ‹è¯•åŠŸèƒ½ï¼šç¡®ä¿ tool calling æ­£å¸¸

### å›æ»šåˆ° qwen3:latest

```yaml
# config/ollama.yaml
ollama:
  model: "qwen3:latest"  # æ”¹å›å®˜æ–¹æ¨¡å‹
```

ç„¶åæ¢å¤ä»£ç ä¸­çš„ system message ä¼ é€’ã€‚

## æ€»ç»“

- âœ… **ç”¨ Modelfile**ï¼šå›ºåŒ– SYSTEM å’Œ PARAMETER
- âœ… **ä¸åŠ  TEMPLATE**ï¼šç»§æ‰¿ qwen3 çš„ tool calling èƒ½åŠ›
- âœ… **ç®€åŒ–ä»£ç **ï¼šæ— éœ€åŠ¨æ€ä¼  system message
- âœ… **å›¢é˜Ÿç»Ÿä¸€**ï¼šæ‰€æœ‰äººä½¿ç”¨ç›¸åŒé…ç½®
